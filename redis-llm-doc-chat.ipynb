{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b692c73",
   "metadata": {},
   "source": [
    "# Using Redis and OpenAI to chat with PDF documents\n",
    "\n",
    "This notebook demonstrates how to use RedisAI and (Azure) OpenAI to chat with PDF documents. The PDF included is\n",
    "a informational brochure about the Chevy Colorado pickup truck.\n",
    "\n",
    "In this notebook, we will use LLamaIndex to chunk, vectorize, and store the PDF document in Redis as vectors\n",
    "alongside associated text. The query interface provided by LLamaIndex will be used to search for relevant\n",
    "information given queries from the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949e6cf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install the requirements\n",
    "%pip install redis pypdf PyPDF2 python-dotenv transformers tiktoken ipywidgets llama_index==0.8.26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47264e32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T12:20:23.988789Z",
     "start_time": "2023-02-10T12:20:23.967877Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import textwrap\n",
    "import openai\n",
    "from langchain.llms import AzureOpenAI, OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from llama_index.vector_stores import RedisVectorStore\n",
    "from llama_index import LangchainEmbedding\n",
    "from llama_index import (\n",
    "    GPTVectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    LLMPredictor,\n",
    "    PromptHelper,\n",
    "    ServiceContext,\n",
    "    StorageContext\n",
    ")\n",
    "import sys\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO) # logging.DEBUG for more verbose output\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2014a346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the .env file in the parent directory into the current environment\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('./.env')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ad91218",
   "metadata": {},
   "source": [
    "# Azure OpenAI and OpenAI\n",
    "\n",
    "The notebook allows the user two choose between using the OpenAI and Azure OpenAI endpoints. Make sure to follow the instructions in the README and set the .env correctly according to whichever API you are using. \n",
    "\n",
    "NOTE: ONLY ONE API CAN BE USED AT A TIME."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0023333d",
   "metadata": {},
   "source": [
    "## Azure OpenAI \n",
    "\n",
    "Here we setup the AzureOpenAI models and API keys that we set by reading from the environment above. The ``PromptHelper`` sets the parameters for the OpenAI model. The classes defined here are used together to provide a QnA interface between the user and the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32a77108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using models: text-embedding-ada-002 and text-davinci-003\n",
      "Using deployments: embed and textgen\n"
     ]
    }
   ],
   "source": [
    "# setup Llama Index to use Azure OpenAI\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_API_BASE\")\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Get the OpenAI model names ex. \"text-embedding-ada-002\"\n",
    "embedding_model = os.getenv(\"OPENAI_EMBEDDING_MODEL\")\n",
    "text_model = os.getenv(\"OPENAI_TEXT_MODEL\")\n",
    "\n",
    "\n",
    "print(f\"Using models: {embedding_model} and {text_model}\")\n",
    "\n",
    "# get the Azure Deployment name for the model\n",
    "embedding_model_deployment = os.getenv(\"AZURE_EMBED_MODEL_DEPLOYMENT_NAME\")\n",
    "text_model_deployment = os.getenv(\"AZURE_TEXT_MODEL_DEPLOYMENT_NAME\")\n",
    "\n",
    "print(f\"Using deployments: {embedding_model_deployment} and {text_model_deployment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c67d58db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "llm = AzureOpenAI(deployment_name=text_model_deployment, model_kwargs={\n",
    "    \"api_key\": openai.api_key,\n",
    "    \"api_base\": openai.api_base,\n",
    "    \"api_type\": openai.api_type,\n",
    "    \"api_version\": openai.api_version,\n",
    "})\n",
    "llm_predictor = LLMPredictor(llm=llm)\n",
    "\n",
    "embedding_llm = LangchainEmbedding(\n",
    "    OpenAIEmbeddings(\n",
    "        model=embedding_model,\n",
    "        deployment=embedding_model_deployment,\n",
    "        openai_api_key= openai.api_key,\n",
    "        openai_api_base=openai.api_base,\n",
    "        openai_api_type=openai.api_type,\n",
    "        openai_api_version=openai.api_version,\n",
    "    ),\n",
    "    embed_batch_size=1,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a31b8dae",
   "metadata": {},
   "source": [
    "## OpenAI\n",
    "\n",
    "The ``OpenAI`` class provides a simple interface to the OpenAI API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ce97716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using models: text-embedding-ada-002 and text-davinci-003\n"
     ]
    }
   ],
   "source": [
    "# setup Llama Index to use Azure OpenAI\n",
    "openai.api_type = \"openai\"\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Get the OpenAI model names ex. \"text-embedding-ada-002\"\n",
    "embedding_model = os.getenv(\"OPENAI_EMBEDDING_MODEL\")\n",
    "text_model = os.getenv(\"OPENAI_TEXT_MODEL\")\n",
    "\n",
    "\n",
    "print(f\"Using models: {embedding_model} and {text_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "076cf33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "llm = OpenAI(model_kwargs={\n",
    "    \"api_key\": openai.api_key,\n",
    "    \"api_base\": openai.api_base,\n",
    "    \"api_type\": openai.api_type,\n",
    "    \"api_version\" : openai.api_version,\n",
    "\n",
    "})\n",
    "llm_predictor = LLMPredictor(llm=llm)\n",
    "\n",
    "embedding_llm = LangchainEmbedding(\n",
    "    OpenAIEmbeddings(\n",
    "        model=embedding_model,\n",
    "        openai_api_version=openai.api_version,\n",
    "        openai_api_key= openai.api_key,\n",
    "        openai_api_base=openai.api_base,\n",
    "        openai_api_type=openai.api_type,\n",
    "    ),\n",
    "    embed_batch_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ff935d",
   "metadata": {},
   "source": [
    "### LLamaIndex\n",
    "\n",
    "[LlamaIndex](https://github.com/jerryjliu/llama_index) (GPT Index) is a project that provides a central interface to connect your LLM's with external data sources. It provides a simple interface to vectorize and store embeddings in Redis, create search indices using Redis, and perform vector search to find context for generative models like GPT.\n",
    "\n",
    "Here we will use it to load in the documents (Chevy Colorado Brochure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68cbd239-880e-41a3-98d8-dbb3fab55431",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T12:20:30.175678Z",
     "start_time": "2023-02-10T12:20:30.172456Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID: cff917df-07b0-4d64-b363-5bc165d455e1\n"
     ]
    }
   ],
   "source": [
    "# load documents\n",
    "documents = SimpleDirectoryReader('./docs').load_data()\n",
    "print('Document ID:', documents[0].doc_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "697a59d2",
   "metadata": {},
   "source": [
    "Llamaindex also works with frameworks like langchain to make prompting and other aspects of a chat based application easier. Here we can use the ``PromptHelper`` class to help us generate prompts for the (Azure) OpenAI model. The will be off by default as it can be tricky to setup correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "147e7678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of output tokens\n",
    "num_output = int(os.getenv(\"OPENAI_MAX_TOKENS\"))\n",
    "# max LLM token input size\n",
    "max_input_size = int(os.getenv(\"CHUNK_SIZE\"))\n",
    "# set maximum chunk overlap\n",
    "max_chunk_overlap = float(os.getenv(\"CHUNK_OVERLAP\"))\n",
    "\n",
    "prompt_helper = PromptHelper(max_input_size, num_output, max_chunk_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "132b7b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define the service we will use to answer questions\n",
    "# if you executive the Azure OpenAI code above, your Azure Models and creds will be used and the same for OpenAI\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm_predictor=llm_predictor,\n",
    "    embed_model=embedding_llm,\n",
    "#    prompt_helper=prompt_helper # uncomment to use prompt_helper.\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd270925",
   "metadata": {},
   "source": [
    "## Initialize Redis as a Vector Database\n",
    "\n",
    "Now we have our documents read in, we can initialize the ``RedisVectorStore``. This will allow us to store our vectors in Redis and create an index.\n",
    "\n",
    "The ``GPTVectorStoreIndex`` will then create the embeddings from the text chunks by calling out to OpenAI's API. The embeddings will be stored in Redis and an index will be created.\n",
    "\n",
    "NOTE: If you didn't set the ``OPENAI_API_KEY`` environment variable, you will get an error here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "788f73b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Redis address: redis://localhost:6379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_redis_conn_from_env(using_ssl=False):\n",
    "    start = \"rediss://\" if using_ssl else \"redis://\"\n",
    "    # if using RBAC\n",
    "    password = os.getenv(\"REDIS_PASSWORD\", None)\n",
    "    username = os.getenv(\"REDIS_USERNAME\", \"default\")\n",
    "    if password != None:\n",
    "        start += f\"{username}:{password}@\"\n",
    "\n",
    "    return start + f\"{os.getenv('REDIS_ADDRESS')}:{os.getenv('REDIS_PORT')}\"\n",
    "\n",
    "\n",
    "# make using_ssl=True to use SSL with ACRE\n",
    "redis_address = format_redis_conn_from_env(using_ssl=False)\n",
    "\n",
    "print(f\"Using Redis address: {redis_address}\")\n",
    "vector_store = RedisVectorStore(\n",
    "    index_name=\"chevy_docs\",\n",
    "    index_prefix=\"blog\",\n",
    "    redis_url=redis_address,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# access the underlying client in the RedisVectorStore implementation to ping the redis instance\n",
    "vector_store.client.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba1558b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T12:20:33.735897Z",
     "start_time": "2023-02-10T12:20:30.404245Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.vector_stores.redis:Deleting index chevy_docs\n",
      "Deleting index chevy_docs\n",
      "Deleting index chevy_docs\n",
      "INFO:llama_index.vector_stores.redis:Creating index chevy_docs\n",
      "Creating index chevy_docs\n",
      "Creating index chevy_docs\n",
      "INFO:llama_index.vector_stores.redis:Added 27 documents to index chevy_docs\n",
      "Added 27 documents to index chevy_docs\n",
      "Added 27 documents to index chevy_docs\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 14521 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 14521 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 14521 tokens\n"
     ]
    }
   ],
   "source": [
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = GPTVectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    storage_context=storage_context,\n",
    "    service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04304299-fc3e-40a0-8600-f50c3292767e",
   "metadata": {},
   "source": [
    "## Start Querying information from the Document\n",
    "\n",
    "Now that we have our document stored in the index, we can ask questions against the index. The index will use the data stored in itself as the knowledge base for chatgpt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35369eda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T12:20:51.328762Z",
     "start_time": "2023-02-10T12:20:33.822688Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.vector_stores.redis:Querying index chevy_docs\n",
      "Querying index chevy_docs\n",
      "Querying index chevy_docs\n",
      "INFO:llama_index.vector_stores.redis:Found 2 results for query with id ['blog_52cde0a6-10fb-4ecd-8619-f0cf3ef74e99', 'blog_67cc5f3b-9aca-4582-8f9d-4fc9d5c1ddac']\n",
      "Found 2 results for query with id ['blog_52cde0a6-10fb-4ecd-8619-f0cf3ef74e99', 'blog_67cc5f3b-9aca-4582-8f9d-4fc9d5c1ddac']\n",
      "Found 2 results for query with id ['blog_52cde0a6-10fb-4ecd-8619-f0cf3ef74e99', 'blog_67cc5f3b-9aca-4582-8f9d-4fc9d5c1ddac']\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 11 tokens\n",
      "> [retrieve] Total embedding token usage: 11 tokens\n",
      "> [retrieve] Total embedding token usage: 11 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1449 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1502 tokens\n",
      "> [get_response] Total LLM token usage: 1502 tokens\n",
      "> [get_response] Total LLM token usage: 1502 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "\n",
      "  The Chevrolet Colorado is available in four models: WT, LT, Z71, and ZR2. There are also special\n",
      "editions available, including the ZR2 Bison Edition, ZR2 Dusk Special Edition, and ZR2 Midnight\n",
      "Special Edition.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What types of variants are available for the Chevrolet Colorado?\")\n",
    "print(\"\\n\", textwrap.fill(str(response), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99212d33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T12:21:10.337294Z",
     "start_time": "2023-02-10T12:20:51.338718Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.vector_stores.redis:Querying index chevy_docs\n",
      "Querying index chevy_docs\n",
      "Querying index chevy_docs\n",
      "INFO:llama_index.vector_stores.redis:Found 2 results for query with id ['blog_28b35a8b-ac42-44a2-9830-a1a7c4770bbe', 'blog_52cde0a6-10fb-4ecd-8619-f0cf3ef74e99']\n",
      "Found 2 results for query with id ['blog_28b35a8b-ac42-44a2-9830-a1a7c4770bbe', 'blog_52cde0a6-10fb-4ecd-8619-f0cf3ef74e99']\n",
      "Found 2 results for query with id ['blog_28b35a8b-ac42-44a2-9830-a1a7c4770bbe', 'blog_52cde0a6-10fb-4ecd-8619-f0cf3ef74e99']\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 14 tokens\n",
      "> [retrieve] Total embedding token usage: 14 tokens\n",
      "> [retrieve] Total embedding token usage: 14 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 983 tokens\n",
      "> [get_response] Total LLM token usage: 983 tokens\n",
      "> [get_response] Total LLM token usage: 983 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "\n",
      "  The maximum towing capacity of the Chevy Colorado is 7,700 lbs. with the available GM-exclusive\n",
      "Duramax® 2.8L Turbo-Diesel engine.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is the maximum towing capacity of the chevy colorado?\")\n",
    "print(\"\\n\", textwrap.fill(str(response), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a028452",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.vector_stores.redis:Querying index chevy_docs\n",
      "Querying index chevy_docs\n",
      "Querying index chevy_docs\n",
      "INFO:llama_index.vector_stores.redis:Found 2 results for query with id ['blog_52cde0a6-10fb-4ecd-8619-f0cf3ef74e99', 'blog_67cc5f3b-9aca-4582-8f9d-4fc9d5c1ddac']\n",
      "Found 2 results for query with id ['blog_52cde0a6-10fb-4ecd-8619-f0cf3ef74e99', 'blog_67cc5f3b-9aca-4582-8f9d-4fc9d5c1ddac']\n",
      "Found 2 results for query with id ['blog_52cde0a6-10fb-4ecd-8619-f0cf3ef74e99', 'blog_67cc5f3b-9aca-4582-8f9d-4fc9d5c1ddac']\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 16 tokens\n",
      "> [retrieve] Total embedding token usage: 16 tokens\n",
      "> [retrieve] Total embedding token usage: 16 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1583 tokens\n",
      "> [get_response] Total LLM token usage: 1583 tokens\n",
      "> [get_response] Total LLM token usage: 1583 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "\n",
      "  The three engine types available for the Chevy Colorado are the 2.5L 4-cylinder, 3.6L V6, and\n",
      "Duramax 2.8L Turbo-Diesel. The main differences between them are in power and performance. The 2.5L\n",
      "4-cylinder engine is the least powerful and offers lower fuel efficiency, while the 3.6L V6 provides\n",
      "more power and acceleration and has better fuel economy. The Duramax 2.8L Turbo-Diesel engine is the\n",
      "most powerful and offers the best fuel efficiency, while also providing the highest maximum trailer\n",
      "weight of 7,700 lbs.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What are the main differences between the three engine types available for the Chevy Colorado?\")\n",
    "print(\"\\n\", textwrap.fill(str(response), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e73a80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
